# 2026-02-22

## Infrastructure: Running OpenLabel on Synology Docker
- Container `openlabel-app` on Synology (192.168.100.200) using `node:20-slim` image with `--network host`
- Workspace mounted at `/volume1/docker/claude-code-workspace:/workspace`
- Code cloned to `/workspace/openlabel` using GitHub PAT
- Need to install `git`, `openssl` after every container restart (not persisted in image)
- Backend: `npx tsx src/index.ts` on :3001, Frontend: `npx next dev -p 3000 -H 0.0.0.0`
- Backend .env needs both `CLERK_SECRET_KEY` AND `CLERK_PUBLISHABLE_KEY`
- Redis on Synology is port 6380 (not 6379), Postgres on 5433
- Old `claude-code` container was deleted and replaced with `openlabel-app`

## Fixes Made
- **Redis optional**: Queue/worker now gracefully handles missing Redis — app starts without it, upload returns 503
- **crypto.randomUUID**: Replaced with `uuid` library — `crypto.randomUUID()` requires HTTPS secure context
- **Format helpers**: All format functions now have null/NaN guards — API can return undefined for some fields
- **Prisma OpenSSL**: `node:20-slim` needs `apt-get install openssl` for Prisma to work

## Frontend Catalog Redesign (Built by Henry)
- Nova failed to deliver — produced no files, no branch, no code
- I built it directly: 5 shared components, redesigned earnings page, artist + track detail pages
- Branch `feature/frontend-catalog-redesign` merged to main
- Lesson reinforced: Nova needs exact scaffolding or fails entirely. Consider building frontend myself going forward.

## Linus Performance
- Query Layer V2: 7/10 on first delivery, fixed 4 issues, second delivery clean
- Release Module V1: 8/10, I fixed 3 issues (shared prisma, status validation, batched date recalc)
- All agents now on Claude Sonnet 4 (`anthropic/claude-sonnet-4-20250514`)

## Jaques
- Given write/edit access, saves research to `/host/home/Obsidian/Jaques/`
- Delivered solid UX research for catalog redesign

## DB State
- Fresh reset on 2026-02-22 — all tables exist, no data
- Both migrations marked as applied (init + add_release_module)

## Discord Command Center — LIVE ✅
- Server: OpenLabel (guild 1475197196696817906)
- 30 channels across 8 categories, Team Internal is private
- 5 bots, each with own token and Discord identity:
  - Henry bot (1475198999366602813) → default agent, all unbound channels
  - Linus bot (1475212382837149899) → backend dev
  - Nova bot (1475213549382144030) → frontend dev
  - Jaques bot (1475213977582702832) → research
  - Suri bot (1475214442806644808) → TBD
- Bindings: each accountId → agentId, mention-based interaction
- Config persisted to /app/openclaw-state/openclaw.json (must copy there or container restart loses changes)
- Discord plugin must be enabled in BOTH channels.discord.enabled AND plugins.entries.discord.enabled
- Guild config lives inside each account, not at top level
- All agents initialized via #dev-general

## Current State — APP WORKING ✅
- All code on main, pushed to GitHub
- App running on Synology at http://192.168.100.200:3000
- 3 reports uploaded: 2 ADA (Dec 2025, Jan 2026) + 1 DistroKid (Apr 2024)
- Earnings page working with all group-by dimensions, date filtering, drill-down
- Seb confirmed "looks good, we got a good version working"

## Major Architecture Decision: Label vs Publishing Separation (from Seb, ~02:20 UTC)
- Publishing income (compositions) must NEVER be mixed with label/master income
- Different companies handle each side — even if same company does both, separate logins
- Label side: DistroKid, ADA, TuneCore, distributors → master recordings (ISRC/UPC)
- Publishing side: ASCAP, BMI, SESAC, HFA, MLC → compositions/works (ISWC)
- Account-level separation: a label user sees only label reports, a publisher sees only publishing reports
- Jaques spawned to research deeply → report at `/host/home/Obsidian/Jaques/LABEL-VS-PUBLISHING-RESEARCH.md`
- This will require: parser classification (label vs publishing), account type model, enforced separation in queries/UI
- We already have implicit hints (ParserCategory DISTRIBUTOR vs PRO, sourceType field) but needs to be explicit

## Royalty Side Tagging — MERGED ✅ (evening session)
- Linus delivered 25 new tests on `feature/royalty-side-tagging`
- Implementation was already on main (schema, migration, services, routes)
- Tests cover: categoryToSide() mapping, backfill, upload pipeline, side filter isolation
- Reviewed: clean diff, +527 lines across 3 test files, no regressions
- Merged to main, pushed, deployed to Synology, migration applied
- First Linus spawn failed silently (OAuth expiry), third attempt succeeded
- App rebuilt on Synology: `git pull` → `npm install` → `prisma generate` → `prisma migrate deploy` → restart both services

## Discord Bot Configuration — Working ✅
- `requireMention: true` works — only the @mentioned bot responds
- Bot-to-bot messaging does NOT work — gateway silently drops messages from its own bots
- Agent-to-agent communication must use `sessions_spawn` / `sessions_send`, not Discord
- Discord is the system of record for humans — all tasks, decisions, updates must be logged there
- Added all bot IDs to users allowlist for each account
- `allowBots: true` set per account (not just top-level)
- All 5 bots assigned the AI Agent role → access to Team Internal channels
- Henry posts to Discord via curl (Bot token + REST API) since the gateway won't process self-messages

## Agent AGENTS.md Files Created
- Created workspace files for Linus, Nova, Jaques, Suri at `~/.openclaw/agents/<name>/agent/AGENTS.md`
- Mandatory rule: log every task on Discord in their respective channel
- Persisted to `/app/openclaw-state/agents/` volume

## Vision Updates — Pushed ✅
- Added "Competitive Moat" section to VISION.md — why agents can't eat OpenLabel
- Added "One Agent, Skills Underneath" UX philosophy — single conversational agent, specialized skills behind the scenes
- Seb's concern: SaaS being eaten by agentic AI — our defense is being the data layer agents plug INTO

## Key Seb Preferences (new)
- Discord is the system of record — everything gets logged there
- Worried about AI eating SaaS — wants differentiation strategy always top of mind
- Confirmed: one agent for users (not multiple), complexity behind curtain
- "It's early here" — Seb is NOT in UTC, don't assume late night

## AI Parser Skill — Phase A MERGED ✅ (late session, ~02:45 UTC)
- Linus delivered: aiParser.ts, aiPrompt.ts, aiValidator.ts, modified reportService.ts
- 50 new tests, +1,781 lines, all passing
- Fixed LLM_ENDPOINT URL construction (needed /chat/completions appended)
- Merged to main, deployed to Synology with LLM keys in .env

## AI Parser Validation Test (02:48 UTC)
- Built test script comparing hard-coded parser output vs AI parser output
- DistroKid: 89% accuracy — 8/9 fields perfect, sourceType mapped to OTHER instead of STREAM
- ASCAP: 89% accuracy — 8/9 fields perfect, artistName mapped to wrong column
- ADA: couldn't test (hard-coded parser didn't detect tab-delimited .txt — separate bug)
- 89% on first pass with zero training is strong baseline

## AI Parser Phase B Spec — Self-Learning (02:55 UTC)
- Key insight from Seb: "does it always need user validation? can it learn without the user?"
- Designed self-validation engine: 4 independent signals (consistency 30%, correlation 25%, plausibility 25%, AI confidence 20%)
- Auto-accept at ≥85% combined score, flag 50-84%, reject <50%
- LearnedParser Prisma model, global (shared across all users)
- Spec at docs/specs/AI-PARSER-PHASE-B.md
- Linus spawned to build it

## Seb's Sentiment
- "Today was an important day" — recognizes the AI parser as a milestone
- Went from 3 hard-coded parsers to AI-powered universal parsing + self-learning in one session

## Late Session (02:30-04:07 UTC Feb 23)

### AI Parser Phase A — MERGED ✅
- 50 tests, +1,781 lines
- Fixed LLM_ENDPOINT URL construction

### AI Parser Validation Results (iterative prompt tuning)
- DistroKid: 89% → 91% (sourceType fixed via field-level sourceTypeMap)
- ADA: 89% → ~100% (fuzzy platform + sourceType matching)
- ASCAP: 78% → 89% (revenue fixed, territory fixed via ISO2 resolution)
- BMI: 80% first pass
- Key fixes: fuzzy matching for platform/sourceType, territory country→ISO2 map, constant-value detection, field-level maps

### AI Parser Phase B — MERGED ✅
- Self-learning + auto-validation: 4-signal engine
- 51 tests, +1,759 lines
- LearnedParser Prisma model, API endpoints, startup registration

### Learning Loop — PROVEN ✅
- BMI test: Upload 1 (unknown) = 18s AI analysis → auto-accepted at 86.35% → learned
- Upload 2 = 1s hash match (18x faster)
- Upload 3 = 1.4s hash match — instant from learned definition

### Revenue Verification — SPEC WRITTEN, LINUS BUILDING
- 5 checks: checksum, fingerprint, LLM sample verify, cross-upload, distribution
- Revenue confidence < 70% = auto-reject (veto power)
- Seb: "80% on revenue could mean millions, is not acceptable"

### Intelligence Improvements Committed
- Universal delimiter detection (comma, tab, pipe, semicolon)
- sourceTypeMap + territoryMap transforms added
- Fuzzy platform matching (YouTube variants, iTunes, etc.)
- Fuzzy sourceType matching (audio stream → STREAM, sale → DOWNLOAD)
- Country name → ISO2 resolution (100+ countries)
- YYYYQ quarter date format support (BMI)
- Date year guard (reject year 20244, only accept 1990-2100)

### Seeding Strategy Defined
- Tier 1 (80% coverage): DistroKid✅, TuneCore, CD Baby, Spotify, Apple, ASCAP✅, BMI✅, ADA✅
- Tier 2: SESAC, SoundExchange, MLC, HFA, Ditto, LANDR, Amuse
- Tier 3: Believe, FUGA, Symphonic, Stem, ONErpm
- Dynamic prompt enhancement planned: learned parsers become examples for future analysis
