# 2026-02-15 — Big Build Day

## OpenLabel MVP Complete Loop
- Built full upload → detect → parse → store → display loop in one session
- Backend: Express API (port 3001) with upload/catalog routes
- Frontend: Next.js 15 + Tailwind dark theme, upload page + catalog page
- Database: PostgreSQL via Prisma on Synology NAS

## Database Setup
- Dedicated container `openlabel-v3-postgres` on Synology 192.168.100.200:5433
- Credentials: `openlabel_v3` / `OL3_xK9mP2vR7nQ`
- DB name: `openlabel_v3`
- Old container `openlabel-postgres` (port 25432) has other data — DO NOT TOUCH
- Schema: Report + RoyaltyEntry models, Decimal(18,8) for revenue

## Synology Access
- SSH: henry@192.168.100.200, password: NjO#@Fl5
- Docker needs `sudo` with `-S` flag and full path `/usr/local/bin/docker`

## Detection Enhancements Merged
- Confidence scoring with detailed breakdowns
- Weighted signature column detection (high-weight columns = more unique)
- Format versioning (drift detection)
- Unknown file handling with near-match suggestions

## Research Completed
- Jaques: Document detection patterns (cross-industry) → research/document-detection-research.md
- Jaques: Tech stack research → research/tech-stack-research.md
  - Recommended: Postgres + Prisma (decided), Fastify + tRPC (future), native Swift + KMP for mobile
  - Drizzle vs Prisma debate → Seb chose Prisma (stability > marginal speed)

## Team Observations
- **Linus** delivers spec-accurate code consistently. Minimal corrections needed. Best agent.
- **Nova** had type mismatches (artist vs artistName, period vs periodStart). Root cause: I gave prose descriptions instead of exact interfaces. Fix: backend-first sequencing + shared types.
- Seb said to use Linus's code, discard Nova's. I rewrote frontend myself with correct types.

## Architecture Decisions
- Prisma over Drizzle (Seb's call — proven, stable, larger ecosystem)
- No auth for now — ship the loop first, add Clerk later
- In-memory fallback not needed since we have Synology Postgres
- `revenue` as Decimal(18,8) — financial precision, never floats

## Key Bug Fixed
- Upload route crashed after Prisma migration: `result.report.entries.length` — entries removed from ReportRecord. Fixed to use `report.parsedRows`.

## Git State
- All on main branch, pushed to github.com/openlabelai/openlabel
- 126 tests green (parsers + API)
- Branches merged: detection-enhancements, mvp-api, prisma-db
- feature/csv-export still unmerged

## TODO (from session)
1. ~~Database~~ ✅
2. ~~Frontend~~ ✅ 
3. Auth (Clerk) — deferred
4. Background processing (BullMQ + Redis)
5. More parsers (ASCAP Writer/Domestic, BMI)
6. Express → Fastify + tRPC migration
7. File storage (R2/S3)
8. Deploy (Railway + Vercel)
9. Mobile (Swift/SwiftUI iOS, Kotlin/KMP Android)

## Session Config
- Seb wants session expiry changed to 365 days (idle mode, idleMinutes: 525600)
- Config change needed in openclaw.config.json5 on gateway host

## Open Issue (RESOLVED)
- "upload failed to fetch" — fixed with Next.js API proxy + body size limit increase

## Hardware Incoming
- Dell Pro Max with NVIDIA GB10 (Grace Blackwell) — arriving in ~3 weeks
- 128GB LPDDR5x unified memory, 1 PFLOP FP4, supports 200B parameter models
- Plan: run local LLM for PDF extraction (Qwen2.5-VL 72B or larger), replace API calls
- Two units can link for 400B+ parameter models

## PDF Parsing Strategy
- Hybrid approach: `pdftotext` for text extraction (local, free) → LLM for structuring
- Build with swappable LLM backend: API now, local Ollama on Dell later
- BMI PDFs confirmed to contain same data as CSVs — needed because some users only get PDFs by email

## Late Night Session (continued into 2026-02-16)

### Background Processing (BullMQ + Redis)
- Redis container `openlabel-v3-redis` on Synology port 6380 (not 6379 — Synology firewall)
- Volume permissions needed chmod 777 for Redis appendonly dir
- BullMQ lock duration increased to 5min for large files (64K row ADA files)
- Upload now returns 202 with jobId, frontend polls /api/jobs/:id
- `?sync=true` query param preserves old synchronous behavior for tests
- Progress reporting: detecting → parsing → storing with real batch percentages

### BMI Parser (4th parser)
- 36 tests, revenue-validated against 3 real CSV files
- Period format: YYYYQ (20244 = Q4 2024)
- Country mapping: full names → ISO codes (61 countries + 3 society aliases)
- Platform mapping: 60+ BMI variants → normalized enum
- Source type: always PERFORMANCE (PRO)
- No ISRC — uses TITLE # (BMI work number) stored in rawData
- Linus delivered clean, merged to main

### PDF Extraction Pipeline
- v1: pdfjs-dist + GPT-4o-mini, 384/871 entries (44% accuracy), 13 minutes, $0.04
- Problem: pdfjs loses column alignment, arbitrary chunk splitting, generic prompts
- v2 spec written: pdftotext -layout, section-aware splitting, exact column descriptions per section type, parallel LLM calls (5 concurrent)
- Linus building v2 now
- Jaques completed PDF extraction research → research/pdf-extraction-research.md

### PDF Research Key Findings
- No music-industry-specific PDF parsers exist commercially — opportunity
- AWS Textract: $0.015/page, proven accuracy
- Camelot (Python): 99%+ on clean docs, free
- Production quality: 95%+ accuracy minimum, 99%+ for financial
- Recommendation: hybrid approach (pdftotext + LLM now, local model on Dell later)

### Infrastructure
- OpenAI API key configured for PDF extraction (GPT-4o-mini)
- Dell Pro Max with GB10 arriving in ~3 weeks (128GB, 1 PFLOP, 200B params)
- Plan: swap LLM_ENDPOINT from OpenAI to local Ollama when Dell arrives

### Features Added
- Delete individual reports: API endpoint + UI button with confirmation
- Server-side sorting: sorts entire catalog via Prisma, not just current page
- Dashboard numbers: 0 decimal places for summary, 4 for entry table
- Multer file filter updated to accept .pdf files
- Frontend accepts PDF uploads with PDF-specific progress phases

### Git State
- All merged to main, pushed
- 163 tests passing (162 + 4 skipped PDF tests)
- Active branches: feature/pdf-extraction-v2 (Linus building)

### Test Totals
- ASCAP: 33 tests
- DistroKid: 15 tests
- ADA: 16 tests
- BMI: 36 tests
- Detection: 15 tests
- Dedup: 16+10 tests
- File hash: 6 tests
- CSV export: 8 tests
- API: 7 tests
