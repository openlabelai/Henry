# 2026-02-14 — First Session

## Who I Am
- **Name:** Henry — System Architect & Coordinator for OpenLabel
- **My human:** Sebasjay (Seb) — CEO of OpenLabel

## OpenLabel
- Royalty intelligence platform for artists, songwriters, producers, record labels
- v2 repo: `openlabelai/openlabel_v2` (reference only)
- v3 repo: `openlabelai/openlabel` | Local: `/host/home/dev/openlabel`
- Architecture docs in Box: `/host/home/Library/CloudStorage/Box-Box/OBSIDIAN/OpenLabel v2/`

## Team
- **Henry (me):** Architect, designs everything, reviews all code, only one who merges
- **Linus:** Backend dev (MiniMax M2) — feature branches only
- **Nova:** Frontend dev (MiniMax M2) — feature branches only
- **Jaques:** Research analyst (MiniMax M2) — gathers info, reports findings
- **Suri:** TBD
- All agents via `sessions_spawn` — Henry-initiated only

## Key Decisions
- I design, agents implement. Don't code directly — spec tasks, delegate, review.
- Parser system is first priority. One at a time, perfect before moving on.
- Header hash detection: O(1) SHA-256 of normalized sorted headers. Tier 2 signature fallback.

## What Was Built Today

### Parser Infrastructure (on main)
- Registry with hash detection, base types, csvReader, parserHelpers
- **ASCAP Publishing Company International CSV parser**
  - 29 tests, 263 rows, $543.80 verified to the cent
  - Hash: `be14cc6afea269f971c6c4b53e390b897220081fe5feed0a82d50c83d917c01c`
  - 26 columns mapped, all rawData preserved

### CSV Export (on feature/csv-export branch)
- **First successful delegation to Linus!** Spec'd the task, he built it, I reviewed and fixed a gap.
- `csvExporter.ts` — exports ParsedRoyaltyEntry[] to normalized CSV with 20 universal columns
- `parseAndExport.ts` — single file CLI: `npx tsx backend/src/scripts/parseAndExport.ts <file>`
- `parseAllAscap.ts` — batch: processes all 6 ASCAP files + combined output
- 7 new tests (36 total, all passing)
- Fix I made: added `programName`/`seriesName` to parser's rawData output (Linus couldn't have known)
- Normalized CSVs generated for all 6 files + combined `all-ascap-pub-intl.normalized.csv`
- Universal columns: source, source_variant, period_start, period_end, amount, currency, territory, work_title, work_id, artist_name, role, right_type, revenue_class, revenue_class_desc, licensor, country_name, member_share, program_name, series_name, raw_metadata_json

### Git — Both branches pushed successfully
- Working GitHub token: `REDACTED_GITHUB_PAT`
- main: `871059f` — parser infrastructure + ASCAP Pub Intl parser
- feature/csv-export: `d74b229` — CSV export + normalized outputs
- feature/csv-export NOT yet merged to main (awaiting Seb's review of CSVs)

## Data Architecture Discussions (Not Built Yet)

### Database Schema Design
- Discussed universal `royalty_entries` table with source tagging
- Key columns: source, source_variant, amount, territory, work_title, artist_name, role, right_type, period
- `raw_metadata` JSONB for source-specific fields
- `uploads` table for file tracking + original file archival
- `entry_hash` SHA-256 for deduplication
- Seb said **don't build DB yet** — export normalized CSVs for analysis first

### Normalization Challenge
- Different reports name the same data differently ("BRUNO MARS" vs "Mars, Bruno")
- Solution: 3-tier normalization pipeline
  1. Static mappings (territory, role, right_type — deterministic per source)
  2. Entity resolution (fuzzy name matching with `entity_aliases` + `work_aliases` tables, user confirmation)
  3. Auto-normalization (string cleaning, case, unicode, "Last, First" → "First Last")
- Not building yet — designing for later

### Original File Archival
- Seb wants original reports stored byte-for-byte for archiving
- Plan: S3/R2/MinIO object storage, referenced by `uploads.storage_path`
- Enables re-parsing, audit trails, dispute resolution

## Telegram Setup — COMPLETE
- Bot token: `REDACTED_TELEGRAM_TOKEN`
- Config added to `/home/node/.openclaw/openclaw.json`
- Seb's Telegram user ID: `792981796`
- Pairing code `N6SA8JZQ` — approved and working
- Seb messaged via Telegram successfully

## ASCAP Report Variants (4 total, 1 done)
1. Writer Report — Domestic (need sample files from Seb)
2. Writer Report — International (need sample files)
3. Publishing Company Report — Domestic (need sample files)
4. **Publishing Company Report — International** ✅ DONE

## Next Steps (for tomorrow)
1. Seb reviews normalized CSVs — any issues with the output?
2. Merge feature/csv-export → main once approved
3. Get sample files for remaining 3 ASCAP variants
4. Build next parser (whichever Seb provides files for)
5. Then: DistroKid, ADA, BMI parsers
6. Start building the normalization/mapping layer

## Files of Note
- `/host/home/dev/openlabel/CONVENTIONS.md` — dev workflow rules
- `/host/home/TOOLS.md` — team architecture notes
- `/host/home/Downloads/ASCAP/` — real ASCAP test data (6 CSV + PDFs)
- `backend/test-datasets/ascap-pub-intl/` — test CSVs + normalized outputs
- `backend/src/scripts/parseAllAscap.ts` — batch export runner
